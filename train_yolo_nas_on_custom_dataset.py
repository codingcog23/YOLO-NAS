# -*- coding: utf-8 -*-
"""train_yolo_nas_on_custom_dataset.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CcfRnkFu-16vjOmplyQ3V3AVGkQxZWMr

# How to Train and Predict YOLO-NAS on Custom Dataset

This notebook is based on official [YOLO-NAS Notebook](https://colab.research.google.com/drive/1q0RmeVRzLwRXW-h9dPFSOchwJkThUy6d?usp=sharing) by DECI AI.

![YOLO-NAS on RF100](https://raw.githubusercontent.com/Deci-AI/super-gradients/master/documentation/source/images/yolo_nas_rf100.png)

## ⚠️ Disclaimer

YOLO-NAS is still very fresh. If you notice that our notebook behaves incorrectly - especially if you experience errors that prevent you from going through the tutorial - don't hesitate! Let us know and open an [issue](https://github.com/roboflow/notebooks/issues) on the Roboflow Notebooks repository.

## Pro Tip: Use GPU Acceleration

If you are running this notebook in Google Colab, navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator`, set it to `GPU`, and then click `Save`. This will ensure your notebook uses a GPU, which will significantly speed up model training times.

## Steps in this Tutorial

In this tutorial, we are going to cover:

- Before you start
- Install YOLO-NAS
- Inference with pre-trained COCO model
- Finding open source datasets
- ⭐️ Training YOLO-NAS on your custom dataset ⭐️
- Load trained model
- Evaluate trained model
- Inference with trained model

## 🔥 Let's begin!

## ⚡ Before you start

Let's make sure that we have access to GPU. We can use `nvidia-smi` command to do that. In case of any problems navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator`, set it to `GPU`, and then click `Save`.
"""

!nvidia-smi

"""## Install YOLO-NAS

"""

from google.colab import drive
drive.mount('/content/drive')

!pip install -q super-gradients==3.1.1
!pip install -q roboflow
!pip install -q supervision

"""### 🚨 Restart the runtime

**After installation is complete, you'll need to restart the runtime after installation completes. Navigate to `Runtime` -> `Restart runtime` and confirm by clicking `Yes` when you see the popup.**

After that, carry on with the notebook starting from the cell below 👇

**NOTE:** To make it easier for us to manage datasets, images and models we create a `HOME` constant.
"""

import os
HOME = os.getcwd()
print(HOME)

"""## Inference with pre-trained COCO model

Start by instantiating a pretrained model. YOLO-NAS architecture comes in three different sizes: `yolo_nas_s`, `yolo_nas_m`, `and yolo_nas_l`. We will use `yolo_nas_l` throughout this notebook. Keep in mind that depending on your use-case your decision may be different. Take a peek at the diagram below visualizing the speed-accuracy tradeoff.

<br>

![YOLO-NAS](https://raw.githubusercontent.com/Deci-AI/super-gradients/master/documentation/source/images/yolo_nas_frontier.png)

"""

import torch

DEVICE = 'cuda' if torch.cuda.is_available() else "cpu"
MODEL_ARCH = 'yolo_nas_l'

from super_gradients.training import models

model = models.get(MODEL_ARCH, pretrained_weights="coco").to(DEVICE)

"""### Use Example Data (Below, We'll Prepare Our Own Custom Dataset)

Let's download few example images. Feel free to replace my images with yours. All you have to do is upload them to the `{HOME}/data` directory.
"""

f"{HOME}/data"

# Commented out IPython magic to ensure Python compatibility.
# %cd {HOME}
!mkdir {HOME}/data
# %cd {HOME}/data

!wget -q https://media.roboflow.com/notebooks/examples/dog.jpeg
!wget -q https://media.roboflow.com/notebooks/examples/dog-2.jpeg
!wget -q https://media.roboflow.com/notebooks/examples/dog-3.jpeg
!wget -q https://media.roboflow.com/notebooks/examples/dog-4.jpeg
!wget -q https://media.roboflow.com/notebooks/examples/dog-5.jpeg
!wget -q https://media.roboflow.com/notebooks/examples/dog-6.jpeg
!wget -q https://media.roboflow.com/notebooks/examples/dog-7.jpeg
!wget -q https://media.roboflow.com/notebooks/examples/dog-8.jpeg

"""### Single Image Inference"""

SOURCE_IMAGE_PATH = f"{HOME}/data/dog-3.jpeg"

import cv2

# image = cv2.imread(SOURCE_IMAGE_PATH)
image = cv2.imread('/content/auto-wbg.jpg')
result = list(model.predict(image, conf=0.35))[0]

"""### Output format

For every image YOLO-NAS will produce `ImageDetectionPrediction` object containing the following fields:
- `image` - `numpy.ndarray` - image used for inference
- `class_names` - `List[str]` - list of categories used for training the model
- `prediction` - `DetectionPrediction` - class instance containing detailed informationabout the obtained detections
   - `bboxes_xyxy` - `numpy.ndarray` of `float32` and `(N, 4)` shape - detection bounding boxes in `xyxy` format
   - `confidence` - `numpy.ndarray` of `float32` and `(N,)` shape - confidence value between `0` and `1`
   - `labels` - `numpy.ndarray` of `float32` and `(N,)` shape - `class_id` related to the index in the `class_names` list
"""

type(result)

"""### Visualize Inference Result

As with other models, you can use Supervision to visualize your results. You can read more about the integration between Supervision and YOLO-NAS [here](https://roboflow.github.io/supervision/detection/core/#supervision.detection.core.Detections.from_yolo_nas), and about visualizing detection [here](https://roboflow.github.io/supervision/detection/annotate/#supervision.detection.annotate.BoxAnnotator.annotate).
"""

# Commented out IPython magic to ensure Python compatibility.
import supervision as sv
import matplotlib.pyplot as plt

def prediction_img(result, output_path):

  detections = sv.Detections(
      xyxy=result.prediction.bboxes_xyxy,
      confidence=result.prediction.confidence,
      class_id=result.prediction.labels.astype(int)
  )

  box_annotator = sv.BoxAnnotator()

  labels = [
      f"{result.class_names[class_id]} {confidence:0.2f}"
      for _, _, confidence, class_id, _
      in detections
  ]

  annotated_frame = box_annotator.annotate(
      scene=image.copy(),
      detections=detections,
      labels=labels
  )

#   %matplotlib inline
  plt.figure(figsize=(12, 12))
  sv.plot_image(annotated_frame)
  cv2.imwrite(output_path + '/' + 'output2.png', annotated_frame)

prediction_img(result=result, output_path='/content/drive/MyDrive/Youtube Videos/Result')

"""# Prediction For Video"""

# Commented out IPython magic to ensure Python compatibility.
def prediction_video(result, output_path, frame):

  detections = sv.Detections(
      xyxy=result.prediction.bboxes_xyxy,
      confidence=result.prediction.confidence,
      class_id=result.prediction.labels.astype(int)
  )

  box_annotator = sv.BoxAnnotator()

  labels = [
      f"{result.class_names[class_id]} {confidence:0.2f}"
      for _, _, confidence, class_id, _
      in detections
  ]

  annotated_frame = box_annotator.annotate(
      scene=frame.copy(),
      detections=detections,
      labels=labels
  )

#   %matplotlib inline
  sv.plot_image(annotated_frame, (12, 12))
  cv2.imwrite(output_path, annotated_frame)

import cv2
def make_prediction_video(video_path):

  video = cv2.VideoCapture(video_path)
  count=0
  while True:
      res, frame = video.read()
      if not res:
          break  # Exit the loop when there are no more frames

      count += 1
      if count % 1 == 0:
          result = list(model.predict(frame, conf=0.35))[0]
          output_path = '/content/drive/MyDrive/Youtube Videos/Result/' + str(count).zfill(4) + ".png"
          prediction_video(result=result, output_path=output_path, frame=frame)

make_prediction_video(video_path='/content/drive/MyDrive/Youtube Videos/Result/cars.mp4')

import cv2
import glob

import cv2
import glob

def write_images_to_video(folder_path, output_video_path, fps=30.0):
    # Get the list of image paths inside the folder
    image_paths = glob.glob(folder_path + "/*.png")

    if len(image_paths) == 0:
        raise ValueError("The folder does not contain any image files.")

    # Read the first image to get its size
    first_image = cv2.imread(image_paths[0])
    height, width, _ = first_image.shape

    # Create a VideoWriter object
    fourcc = cv2.VideoWriter_fourcc('X', 'V', 'I', 'D')  # Try 'XVID' as the codec
    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))

    # Write each image to the video
    for image_path in image_paths:
        image = cv2.imread(image_path)
        # image_bgr = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)  # Convert RGB to BGR
        out.write(image)

    # Release the VideoWriter and close the video file
    out.release()


# Example usage
write_images_to_video(folder_path='/content/drive/MyDrive/Youtube Videos/Result',
                      output_video_path='/content/drive/MyDrive/Youtube Videos/Result/prediction2.mp4',
                      fps=30.0)